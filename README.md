# Multi-Stack DevOps Infrastructure Automation

A complete infrastructure automation project deploying a polyglot microservices voting application on AWS using Terraform and Ansible.

## üìã Project Overview

This project demonstrates infrastructure as code (IaC) and configuration management practices by deploying a multi-tier voting application across AWS EC2 instances.

### Application Architecture

**Vote Application** (Python/Flask) ‚Üí **Redis** (in-memory queue) ‚Üí **Worker** (.NET) ‚Üí **PostgreSQL** (persistent storage) ‚Üê **Result Application** (Node.js/Express)

### Infrastructure Architecture

- **3-Tier Architecture** across 3 EC2 instances
- **Public Subnet**: Frontend instance (Vote + Result apps)
- **Private Subnet**: Backend instance (Redis + Worker)
- **Private Subnet**: Database instance (PostgreSQL)
- **Security**: Frontend acts as bastion host for private instance access

## üóÇÔ∏è Project Structure

```
project_multistack_devops_app/
‚îú‚îÄ‚îÄ terraform/                    # Infrastructure as Code
‚îÇ   ‚îú‚îÄ‚îÄ main.tf                  # Project metadata
‚îÇ   ‚îú‚îÄ‚îÄ provider.tf              # AWS provider configuration
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf             # Input variables
‚îÇ   ‚îú‚îÄ‚îÄ network.tf               # VPC, subnets, routing
‚îÇ   ‚îú‚îÄ‚îÄ security.tf              # Security groups
‚îÇ   ‚îú‚îÄ‚îÄ instances.tf             # EC2 instances
‚îÇ   ‚îú‚îÄ‚îÄ cloudwatch.tf            # CloudWatch monitoring
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf               # Output values
‚îÇ   ‚îî‚îÄ‚îÄ terraform-backend/       # Remote state backend setup
‚îÇ
‚îú‚îÄ‚îÄ ansible/                      # Configuration Management
‚îÇ   ‚îú‚îÄ‚îÄ ansible.cfg              # Ansible configuration
‚îÇ   ‚îú‚îÄ‚îÄ inventory/hosts.yml      # Host inventory (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ group_vars/              # Variable definitions
‚îÇ   ‚îî‚îÄ‚îÄ playbooks/
‚îÇ       ‚îú‚îÄ‚îÄ install-docker.yml   # Install Docker
‚îÇ       ‚îú‚îÄ‚îÄ deploy-*-cli.yml     # Component deployment playbooks
‚îÇ       ‚îú‚îÄ‚îÄ deploy-monitoring.yml # Prometheus/Grafana
‚îÇ       ‚îú‚îÄ‚îÄ deploy-app-metrics.yml # Redis/Postgres exporters
‚îÇ       ‚îú‚îÄ‚îÄ setup-cloudwatch.yml # CloudWatch Agent
‚îÇ       ‚îú‚îÄ‚îÄ test-connectivity.yml # Network tests
‚îÇ       ‚îú‚îÄ‚îÄ check-logs.yml       # Container logs
‚îÇ       ‚îî‚îÄ‚îÄ stop-all.yml         # Stop all containers
‚îÇ
‚îú‚îÄ‚îÄ monitoring/                   # Monitoring & Demo Scripts
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/              # Prometheus configs
‚îÇ   ‚îú‚îÄ‚îÄ grafana/                 # Grafana dashboards
‚îÇ   ‚îú‚îÄ‚îÄ cloudwatch/              # CloudWatch configs
‚îÇ   ‚îú‚îÄ‚îÄ quick-stress.sh          # Load testing (random votes)
‚îÇ   ‚îú‚îÄ‚îÄ stress-test.sh           # Advanced load testing
‚îÇ   ‚îú‚îÄ‚îÄ vote-cats.sh             # Vote for cats demo
‚îÇ   ‚îú‚îÄ‚îÄ vote-dogs.sh             # Vote for dogs demo
‚îÇ   ‚îú‚îÄ‚îÄ reset-db-simple.sh       # Database reset
‚îÇ   ‚îú‚îÄ‚îÄ check-votes.sh           # Vote count checker
‚îÇ   ‚îî‚îÄ‚îÄ *.md                     # Monitoring documentation
‚îÇ
‚îú‚îÄ‚îÄ presentation/                 # Project Presentation
‚îÇ   ‚îú‚îÄ‚îÄ PRESENTATION.md          # Marp presentation
‚îÇ   ‚îú‚îÄ‚îÄ images/                  # Presentation images
‚îÇ   ‚îú‚îÄ‚îÄ generate-presentation.sh # PDF generator
‚îÇ   ‚îî‚îÄ‚îÄ *.md                     # Presentation guides
‚îÇ
‚îú‚îÄ‚îÄ docs/                         # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ ANSIBLE_EXPLAINED.md     # Ansible architecture
‚îÇ   ‚îú‚îÄ‚îÄ ANSIBLE_CONTROL_NODE.md  # Control node setup
‚îÇ   ‚îú‚îÄ‚îÄ ANSIBLE_GALAXY_ROLES.md  # Galaxy roles info
‚îÇ   ‚îú‚îÄ‚îÄ MONITORING_ARCHITECTURE.md # Monitoring deep dive
‚îÇ   ‚îú‚îÄ‚îÄ COMPONENTS_GUIDE.md      # Component architecture
‚îÇ   ‚îî‚îÄ‚îÄ QUICK_REFERENCE.md       # Quick reference guide
‚îÇ
‚îî‚îÄ‚îÄ README.md                     # This file
```

## üöÄ Quick Start Guide

### Prerequisites

1. **AWS Account** with appropriate permissions
2. **Terraform** >= 1.6.0 installed
3. **Ansible** installed with Docker collection
4. **AWS CLI** configured with credentials
5. **SSH Key Pair** created in AWS (ap-northeast-2 region)
6. **Docker Hub Account** with published images

### Step 1: Configure Environment Variables

Copy the example environment file and update with your values:

```bash
cp .env.example .env
# Edit .env with your actual IP addresses after Terraform deployment
```

### Step 2: Deploy Infrastructure with Terraform

#### 2.1: Set Up Remote State Backend (Optional but Recommended)

```bash
cd terraform/terraform-backend/

# Create terraform.tfvars
cat > terraform.tfvars << EOF
aws_region = "ap-northeast-2"
project_name = "bttf-voting-app"
environment = "dev"
EOF

# Initialize and deploy
terraform init
terraform plan
terraform apply

# Note the outputs - you'll need these for the main project
terraform output
```

#### 1.2: Deploy Main Infrastructure

```bash
cd ../  # Back to terraform/ directory

# Create terraform.tfvars
cat > terraform.tfvars << EOF
aws_region = "ap-northeast-2"
key_pair_name = "martin-ap-northeast-2-key"
my_ip = "YOUR_PUBLIC_IP/32"
EOF

# Initialize Terraform
terraform init

# Review the plan
terraform plan

# Deploy infrastructure
terraform apply

# Save the outputs
terraform output > ../deployment-ips.txt
```

Your infrastructure is now created! Note the IP addresses from the output.

### Step 2: Configure Ansible and Deploy Applications

#### 2.1: Automatic Inventory Update (Recommended)

```bash
cd ../ansible/

# Run the update script
./update-inventory.sh
```

This script will:
- Extract IP addresses from Terraform state
- Update the Ansible inventory
- Optionally update your SSH config

#### 2.2: Manual Inventory Update (Alternative)

If you prefer manual setup:

```bash
# Get IPs from Terraform
cd ../terraform/
terraform output

# Update ansible/inventory/hosts.yml with the IPs
cd ../ansible/
nano inventory/hosts.yml
# Replace <FRONTEND_PUBLIC_IP>, <BACKEND_PRIVATE_IP>, <DB_PRIVATE_IP>

# Update group_vars/all.yml with your Docker Hub username
nano group_vars/all.yml
# Change: dockerhub_username: "your-dockerhub-username"
```

#### 2.3: Configure SSH Bastion Access

See `ansible/SSH_BASTION_SETUP.md` for detailed instructions.

Quick version - add to `~/.ssh/config`:

```
Host frontend-instance
  HostName <FRONTEND_PUBLIC_IP>
  User ubuntu
  IdentityFile ~/.ssh/martin-ap-northeast-2-key.pem
  StrictHostKeyChecking no

Host backend-instance
  HostName <BACKEND_PRIVATE_IP>
  User ubuntu
  IdentityFile ~/.ssh/martin-ap-northeast-2-key.pem
  ProxyJump frontend-instance
  StrictHostKeyChecking no

Host db-instance
  HostName <DB_PRIVATE_IP>
  User ubuntu
  IdentityFile ~/.ssh/martin-ap-northeast-2-key.pem
  ProxyJump frontend-instance
  StrictHostKeyChecking no
```

#### 2.4: Test Ansible Connectivity

```bash
cd ansible/

# Install Ansible Docker collection
ansible-galaxy collection install community.docker

# Test connectivity
ansible all -m ping
```

Expected: All hosts return "pong"

#### 2.5: Install Docker on All Instances

```bash
ansible-playbook playbooks/install-docker.yml
```

This takes 2-3 minutes per instance.

#### 2.6: Deploy All Applications

```bash
ansible-playbook playbooks/deploy-all.yml
```

This will deploy:
1. PostgreSQL on database instance
2. Redis and Worker on backend instance
3. Vote and Result apps on frontend instance

### Step 3: Access and Test the Application

```bash
# Get the frontend public IP
cd ../terraform/
FRONTEND_IP=$(terraform output -raw frontend_public_ip)

echo "Vote App:   http://$FRONTEND_IP:80"
echo "Result App: http://$FRONTEND_IP:5001"
```

Open your browser:
- **Vote App**: Cast a vote for Cats or Dogs
- **Result App**: See real-time vote tallies

## üîß Common Operations

### Check Application Logs

```bash
cd ansible/
ansible-playbook playbooks/check-logs.yml
```

### Test Service Connectivity

```bash
ansible-playbook playbooks/test-connectivity.yml
```

### Restart Services

```bash
# Stop all containers
ansible-playbook playbooks/stop-all.yml

# Redeploy
ansible-playbook playbooks/deploy-all.yml
```

### SSH into Instances

```bash
# Frontend (direct)
ssh frontend-instance

# Backend (via bastion)
ssh backend-instance

# Database (via bastion)
ssh db-instance
```

### Check Container Status

```bash
ssh frontend-instance
docker ps
docker logs vote
docker logs result
```

## üêõ Troubleshooting

### Vote App Not Working

**Symptom**: No checkmark after voting

**Solution**: Check Redis connectivity
```bash
ssh frontend-instance
docker exec vote env | grep REDIS
telnet <BACKEND_IP> 6379
```

### Result App Shows Zero Votes

**Symptom**: Vote count doesn't update

**Solution**: Check Worker logs
```bash
ssh backend-instance
docker logs worker
```

Verify Worker can connect to both Redis and PostgreSQL.

### Cannot SSH to Private Instances

**Solution**: Check SSH config and security groups

```bash
# Test SSH config
ssh -v backend-instance

# Verify security groups in AWS Console:
# Backend SG should allow SSH (22) from Frontend SG
```

### Ansible Connection Failed

**Solution**: Verify inventory and SSH key permissions

```bash
chmod 400 ~/.ssh/martin-ap-northeast-2-key.pem
ansible all -m ping -vvv  # Verbose mode for debugging
```

See `ansible/README.md` for detailed troubleshooting.

## üîê Security Considerations

1. **SSH Access**: Restricted to your IP only (via `my_ip` variable)
2. **Private Subnets**: Backend and database not exposed to internet
3. **Security Groups**: Proper port restrictions between tiers
4. **Bastion Host**: Frontend instance for secure access to private instances
5. **State Files**: Stored in S3 with encryption and versioning
6. **Secrets**: Never commit `terraform.tfvars` or SSH keys

## üéØ Project Learning Outcomes

- ‚úÖ Infrastructure as Code with Terraform
- ‚úÖ Multi-tier AWS architecture (VPC, subnets, security groups)
- ‚úÖ Configuration Management with Ansible
- ‚úÖ Docker containerization and orchestration
- ‚úÖ Bastion host and SSH jump host configuration
- ‚úÖ Microservices communication patterns
- ‚úÖ DevOps best practices and automation

## üìö Documentation

- [Ansible README](ansible/README.md) - Complete Ansible guide
- [SSH Bastion Setup](ansible/SSH_BASTION_SETUP.md) - SSH configuration
- [Terraform Analysis](TERRAFORM_ANALYSIS.md) - Infrastructure analysis

## üöß Future Enhancements

- [ ] Add Application Load Balancer (ALB)
- [ ] Multi-AZ deployment for high availability
- [ ] CloudWatch monitoring and alerts
- [ ] Auto Scaling Groups
- [ ] HTTPS with SSL certificates
- [ ] CI/CD pipeline with GitHub Actions
- [ ] Migrate to managed services (RDS, ElastiCache)

## üìù Project Notes

**Technologies Used**:
- **Infrastructure**: Terraform, AWS (EC2, VPC, Security Groups)
- **Configuration**: Ansible, Docker
- **Applications**: Python (Flask), Node.js (Express), .NET (Worker), Redis, PostgreSQL

**Region**: ap-northeast-2 (Seoul)
**Environment**: Development

## ü§ù Contributing

This is a learning project for the IronHack DevOps Bootcamp. Feel free to use it as a reference for your own projects!

## üìÑ License

Educational project - free to use and modify.

---

**Author**: Marty McFly
**Project**: IronHack DevOps Bootcamp - Project 1
**Date**: November 2024
